{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "#import oil.augLayers as augLayers\n",
    "from oil.model_trainers.classifier import Classifier\n",
    "from oil.datasetup.datasets import CIFAR10, C10augLayers\n",
    "from oil.datasetup.dataloaders import getLabLoader\n",
    "from oil.architectures.img_classifiers.smallconv import smallCNN\n",
    "from oil.utils.utils import cosLr, loader_to\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oil.lazy.lazy_matrix import LazyMatrix, Lazy\n",
    "from oil.lazy.lazy_types import LazyAvg\n",
    "from oil.utils.utils import reusable\n",
    "from oil.lazy.linalg.VRmethods import GradLoader, oja_grad2,SGHA_grad2,SGD,SVRG, SGHA_grad,oja_subspace_grad,SGHA_subspace_grad2,SGHA_subspace_grad\n",
    "from oil.logging.lazyLogger import LazyLogger\n",
    "from oil.lazy.linalg.lanczos import power_method\n",
    "from oil.lazy.hessian import Hessian, Fisher, autoHvpBatch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.linalg\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Creating Train, Dev split         with 50000 Train and 0 Dev\n"
     ]
    }
   ],
   "source": [
    "train_epochs = 100\n",
    "net_config =        {'numClasses':10,'k':16}\n",
    "loader_config =     {'amnt_dev':0,'lab_BS':256,'dataseed':0,'num_workers':1}\n",
    "opt_config =        {'lr':.1, 'momentum':.9, 'weight_decay':1e-4, 'nesterov':True}\n",
    "sched_config =      {'cycle_length':train_epochs,'cycle_mult':1}\n",
    "trainer_config =    {'log_args':{'minPeriod':0.1}}\n",
    "all_hypers = {**net_config,**loader_config,**opt_config,**sched_config,**trainer_config}\n",
    "trainer_config['log_dir'] = os.path.expanduser('~/tb-experiments/smallcnn/')\n",
    "\n",
    "def makeTrainer():\n",
    "    device = torch.device('cuda')\n",
    "    CNN = smallCNN(**net_config).to(device)\n",
    "    fullCNN = nn.Sequential(C10augLayers(),CNN)\n",
    "    trainset, testset = CIFAR10(False, '~/datasets/cifar10/')\n",
    "\n",
    "    dataloaders = {}\n",
    "    dataloaders['test'] = DataLoader(testset, batch_size=256,shuffle=False, num_workers=1)\n",
    "    dataloaders['train'], dataloaders['dev'] = getLabLoader(trainset,**loader_config)\n",
    "    dataloaders = {k: loader_to(device)(v) for k,v in dataloaders.items()}\n",
    "\n",
    "    opt_constr = lambda params: optim.SGD(params, **opt_config)\n",
    "    lr_sched = cosLr(**sched_config)\n",
    "    return Classifier(fullCNN,dataloaders,opt_constr,lr_sched,**trainer_config,tracked_hypers=all_hypers)\n",
    "\n",
    "trainer = makeTrainer()\n",
    "#trainer.train(train_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint '/home/marc/tb-experiments/smallcnn/checkpoints/c.100.ckpt'\n",
      "0.8731\n",
      "45114\n"
     ]
    }
   ],
   "source": [
    "#trainer.save_checkpoint()\n",
    "trainer.load_checkpoint()\n",
    "print(trainer.getAccuracy(trainer.dataloaders['test']))\n",
    "print(sum(p.numel() for p in trainer.model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model.eval();\n",
    "H = Hessian(trainer.model,trainer.dataloaders['train'])\n",
    "F = Fisher(trainer.model,trainer.dataloaders['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0 = H.xp.new_randn(H,[H.shape[-1]])\n",
    "trainer.model.device = next(trainer.model.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torch.nn.functional as F\n",
    "%load_ext line_profiler\n",
    "for mb in trainer.dataloaders['train']:\n",
    "    break\n",
    "#%timeit F.cross_entropy(trainer.model(mb[0]),mb[1]).backward()\n",
    "#%timeit H@w0\n",
    "#%prun H@w0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = GradLoader(SGHA_grad,[H,F])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Lazy Average from iterable of minibatches\n",
    "#grads = GradLoader(oja_grad2,[F])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup code for logging\n",
    "logger = LazyLogger(**{'no_print':False, 'minPeriod':0.1, 'timeFrac':1})\n",
    "logger.i = 0 # annoying but we will add some temporary state to keep track of step\n",
    "def log(w,lr,grad):\n",
    "    logger.i+=1\n",
    "    with logger as do_log:\n",
    "        if do_log:\n",
    "            wallclocktime = time.time()\n",
    "            metrics = {}\n",
    "            metrics[r\"$||\\nabla L(w)||$\"] = np.linalg.norm(grad.cpu().numpy())\n",
    "            #metrics[r\"$\\frac{w^TFw}{w^Tw}$\"] = (w@(F@w)/(w@w)).cpu().numpy()\n",
    "            metrics[r\"$\\frac{w^THw}{w^TFw}$\"] = (w@(H@w)/(w@(F@w))).cpu().numpy()\n",
    "            logger.add_scalars('metrics',metrics,step=logger.i)\n",
    "            logger.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3b894cc4b914a23b45643e48610ed26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   $||\\nabla L(w)||$  $\\frac{w^THw}{w^TFw}$\n",
      "1           0.535721               1.005126\n",
      "    $||\\nabla L(w)||$  $\\frac{w^THw}{w^TFw}$\n",
      "99           2.051666               1.005309\n",
      "     $||\\nabla L(w)||$  $\\frac{w^THw}{w^TFw}$\n",
      "197           3.950673                1.00401\n",
      "     $||\\nabla L(w)||$  $\\frac{w^THw}{w^TFw}$\n",
      "295           7.371708               1.010033\n",
      "     $||\\nabla L(w)||$  $\\frac{w^THw}{w^TFw}$\n",
      "393           0.493606               1.025473\n",
      "     $||\\nabla L(w)||$  $\\frac{w^THw}{w^TFw}$\n",
      "491           1.159195               1.049635\n"
     ]
    }
   ],
   "source": [
    "w0 = H.xp.new_randn(H,[H.shape[-1]])\n",
    "trainer.model.device = next(trainer.model.parameters()).device\n",
    "w0 /= torch.norm(w0)\n",
    "lr = lambda e: .01#*cosLr(num_epochs)(e)\n",
    "num_epochs =20\n",
    "wf = SVRG(grads,w0,lr,num_epochs,log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "f = plt.figure()\n",
    "logger.scalar_frame.plot(logy=True)\n",
    "plt.ylabel('Relative Error')\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.legend()\n",
    "#f.savefig(\"VR_PCA.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.scalar_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
