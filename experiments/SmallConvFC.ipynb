{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "os.sys.path.append(\"/home/izmailovpavel/Documents/Projects/pristine-ml\")\n",
    "os.sys.path.append(\"/home/izmailovpavel/Documents/Projects/mode-geometry/\")\n",
    "import torch, torchvision\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.linalg\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from itertools import accumulate, starmap, islice\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from mpmath import mp; mp.dps = 120; mp.prec =300\n",
    "from oil.utils.utils import multiGen, cur\n",
    "from oil.utils.utils import cosLr\n",
    "from oil.extra.eigen2 import oja_grad,oja_grad2, SGHA_grad,SGHA_grad2, GradLoader\n",
    "from oil.extra.eigen2 import SGD,SVRG, H_gen\n",
    "#from oil.extra.mvm import flatten, unflatten_like, autoHvpBatch, autoFvpBatch\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import VGG16\n",
    "from torchvision.datasets import CIFAR100\n",
    "import torch.nn.functional as F\n",
    "import tqdm\n",
    "import data\n",
    "import models\n",
    "import utils\n",
    "import understanding_utils\n",
    "from understanding_utils import UnderstandingNetwork\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "You are going to run models on the test set. Are you sure?\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "path = \"/home/izmailovpavel/datasets/cifar100/\"\n",
    "loaders, num_classes = data.loaders(\n",
    "    \"CIFAR10\",\n",
    "    \"/home/izmailovpavel/datasets/\",\n",
    "    128,\n",
    "    4,\n",
    "    \"VGG\",\n",
    "    True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "num_classes = 10\n",
    "criterion = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nll': 0.4700113780975342, 'accuracy': 84.84, 'loss': 0.4700113780975342}\n"
     ]
    }
   ],
   "source": [
    "architecture = getattr(models, \"SmallConvFC\")\n",
    "\n",
    "model = architecture.base(num_classes=num_classes, **architecture.kwargs)\n",
    "model.cuda()\n",
    "checkpoint = torch.load(\"/home/izmailovpavel/Documents/ckpts/c10/smallconvfc/run1/checkpoint-200.pt\")\n",
    "model.load_state_dict(checkpoint['model_state'])\n",
    "print(utils.test(loaders[\"test\"], model, criterion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134122"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = 0\n",
    "for param in model.parameters():\n",
    "    total += param.numel()\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def vec_to_model(vec):\n",
    "#     new_model = architecture.base(num_classes=num_classes, **architecture.kwargs).cuda()\n",
    "#     prev_i = 0\n",
    "#     for param in new_model.parameters():\n",
    "#         param.data = vec[prev_i:prev_i+param.numel()].reshape(param.shape).data\n",
    "#         prev_i += param.numel()\n",
    "#     return new_model\n",
    "        \n",
    "# def model_to_vec(model):\n",
    "#     vec = []\n",
    "#     for param in model.parameters():\n",
    "#         vec.append(param.reshape(-1))\n",
    "#     return torch.cat(vec)\n",
    "\n",
    "def flatten_params(param_lst):\n",
    "    return torch.cat([param.reshape(-1) for param in param_lst])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_vec = Variable(torch.zeros(134122), requires_grad=True)\n",
    "param_vec.data = model_to_vec(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = vec_to_model(param_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 84.84, 'loss': 0.4700113780975342, 'nll': 0.4700113780975342}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.test(loaders[\"test\"], new_model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hessian():\n",
    "    eps = 1e-5\n",
    "    for i, (x, y) in enumerate(loaders[\"train\"]):\n",
    "        model.zero_grad()\n",
    "        x = Variable(x).cuda()\n",
    "        y = Variable(y).cuda()\n",
    "        batch_size = x.shape[0]\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "        def HessVec(v):\n",
    "            grad_f = torch.autograd.grad(loss, model.parameters(), create_graph=True)#, retain_graph=True)\n",
    "            grad_f = flatten_params(grad_f)\n",
    "            z = grad_f @ v\n",
    "            z.backward(retain_graph=False)\n",
    "            return flatten_params([param.grad / batch_size for param in model.parameters()])\n",
    "        if i > 5:\n",
    "            break\n",
    "        yield [HessVec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def FullHessVec(vec):\n",
    "#     ans = torch.zeros_like(vec)\n",
    "#     for Hv in Hessian():\n",
    "#         ans += Hv(vec)\n",
    "#     return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([134122])\n",
      "torch.Size([134122])\n",
      "torch.Size([134122])\n",
      "torch.Size([134122])\n",
      "torch.Size([134122])\n",
      "torch.Size([134122])\n",
      "torch.Size([134122])\n",
      "torch.Size([134122])\n",
      "torch.Size([134122])\n",
      "torch.Size([134122])\n",
      "torch.Size([134122])\n",
      "torch.Size([134122])\n"
     ]
    }
   ],
   "source": [
    "param_vec = Variable(torch.randn(134122), requires_grad=True).cuda()\n",
    "param_vec.data /= torch.norm(param_vec)\n",
    "param_vec2 = Variable(torch.randn(134122), requires_grad=True).cuda()\n",
    "param_vec2.data /= torch.norm(param_vec2)\n",
    "for Hv in Hessian():\n",
    "#     break\n",
    "#     \n",
    "#     param_vec.data *= 2\n",
    "    print(Hv[0](param_vec).shape)\n",
    "for Hv in Hessian():\n",
    "    print(Hv[0](param_vec2).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = GradLoader(oja_grad, multiGen(Hessian))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = []\n",
    "ws = []\n",
    "\n",
    "log = lambda w,lrr,_: (lrs.append(lrr),ws.append(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sas\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "one of the variables needed for gradient computation has been modified by an inplace operation",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-254-3b6396c7b60c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVRG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Projects/pristine-ml/oil/extra/eigen2.py\u001b[0m in \u001b[0;36mSVRG\u001b[0;34m(grads, w, w_a, lr, num_epochs, log)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgrad\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sas\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mgrad_vr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#grad(w) - grad(w_a) + grad_a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;31m#             w.data = w.data - lr(epoch)*grad_vr.data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m#             log(w, lr(epoch), grad_a)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Projects/pristine-ml/oil/utils/utils.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(*args, **kwArgs)\u001b[0m\n\u001b[1;32m    164\u001b[0m                     \u001b[0;31m#print(newArgs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m                     \u001b[0;31m#print(newKwArgs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnewArgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnewKwArgs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# time to evaluate func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnewArgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnewKwArgs\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m# returns a new 'f'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Projects/pristine-ml/oil/extra/eigen2.py\u001b[0m in \u001b[0;36moja_grad\u001b[0;34m(A, w)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0moja_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mAw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAw\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mAw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-240-6439c29773f9>\u001b[0m in \u001b[0;36mHessVec\u001b[0;34m(v)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mgrad_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflatten_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_f\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mflatten_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation"
     ]
    }
   ],
   "source": [
    "w0 = Variable(torch.randn(134122), requires_grad=True).cuda()\n",
    "w0 /= torch.norm(w0)\n",
    "w = Variable(torch.randn(134122), requires_grad=True).cuda()\n",
    "\n",
    "lr = lambda e: .3*.05#*2e-1*cosLr(num_epochs)(e)\n",
    "num_epochs = 10\n",
    "\n",
    "w = SVRG(grads,w0,w,lr,num_epochs,log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ojas_grad(Aw, w):\n",
    "    return -(Aw - (w@Aw)*w)\n",
    "\n",
    "def SGD(matvec, w, grad_fun, lr, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        for grad in grad_multigen:\n",
    "            w = w - lr(epoch)*grad(w)\n",
    "            log(w, lr(epoch))\n",
    "    return w"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
