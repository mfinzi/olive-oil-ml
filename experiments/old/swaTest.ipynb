{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch, torchvision\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import os\n",
    "#import oil.augLayers as augLayers\n",
    "from oil.model_trainers.classifier import Classifier\n",
    "from oil.datasetup.datasets import CIFAR10, C10augLayers\n",
    "from oil.datasetup.dataloaders import getUnlabLoader, getLabLoader\n",
    "from oil.architectures.networkparts import layer13,ConvSmallNWN\n",
    "from oil.utils.utils import cosLr, loader_to\n",
    "from oil.utils.optim import AutoSWA\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_epochs = 100\n",
    "net_config =        {'numClasses':10}\n",
    "loader_config =     {'amnt_dev':5000,'lab_BS':50,'dataseed':0,'num_workers':4}\n",
    "opt_config =        {'lr':.1, 'momentum':.9, 'weight_decay':1e-4, 'nesterov':True}\n",
    "sched_config =      {'cycle_length':train_epochs,'cycle_mult':1}\n",
    "trainer_config =    {}\n",
    "\n",
    "trainer_config['log_dir'] = os.path.expanduser('~/tb-experiments/baselineSWA/')\n",
    "trainer_config['description'] = 'Test being made'\n",
    "\n",
    "def makeTrainer():\n",
    "    device = torch.device('cuda')\n",
    "    CNN = layer13(**net_config).to(device)\n",
    "    fullCNN = nn.Sequential(C10augLayers(),CNN)\n",
    "    trainset, testset = CIFAR10(False, '~/datasets/cifar10/')\n",
    "\n",
    "    dataloaders = {}\n",
    "    dataloaders['train'], dataloaders['dev'] = getLabLoader(trainset,**loader_config)\n",
    "    dataloaders = {k: loader_to(device)(v) for k,v in dataloaders.items()}\n",
    "\n",
    "    opt_constr = lambda params: AutoSWA(optim.SGD(params, **opt_config))\n",
    "    lr_sched = cosLr(**sched_config)\n",
    "    return Classifier(fullCNN, dataloaders, opt_constr, lr_sched, **trainer_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Creating Train, Dev split         with 45000 Train and 5000 Dev\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d799e1642d2b4699aefa7c701ccd2123",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): RandomTranslate(max_trans=4)\n",
      "    (1): RandomHorizontalFlip()\n",
      "  )\n",
      "  (1): layer13(\n",
      "    (activation): LeakyReLU(negative_slope=0.1)\n",
      "    (conv1a): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bn1a): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv1b): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bn1b): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv1c): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bn1c): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (mp1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (drop1): Dropout(p=0.5)\n",
      "    (conv2a): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bn2a): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2b): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bn2b): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2c): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bn2c): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (mp2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (drop2): Dropout(p=0.5)\n",
      "    (conv3a): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (bn3a): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3b): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (bn3b): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3c): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (bn3c): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (ap3): AvgPool2d(kernel_size=6, stride=2, padding=0)\n",
      "    (fc1): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "     Dev_Acc  Minibatch_Loss   lr\n",
      "901      0.1        2.327364  0.1\n",
      "      Dev_Acc  Minibatch_Loss        lr\n",
      "3231  0.46024        1.524056  0.099941\n",
      "       Dev_Acc  Minibatch_Loss        lr\n",
      "5543  0.602042        1.259044  0.099677\n",
      "       Dev_Acc  Minibatch_Loss        lr\n",
      "7859  0.664332        0.945618  0.099311\n",
      "        Dev_Acc  Minibatch_Loss        lr\n",
      "10170  0.720559        0.749341  0.098636\n",
      "        Dev_Acc  Minibatch_Loss        lr\n",
      "12486  0.761939        0.707225  0.097851\n",
      "        Dev_Acc  Minibatch_Loss        lr\n",
      "14796  0.788231        0.674073  0.096683\n",
      "       Dev_Acc  Minibatch_Loss        lr\n",
      "17108  0.80827         0.57424  0.095133\n",
      "        Dev_Acc  Minibatch_Loss        lr\n",
      "19421  0.821524        0.556165  0.093531\n",
      "        Dev_Acc  Minibatch_Loss        lr\n",
      "21732  0.838443        0.507369  0.091487\n",
      "        Dev_Acc  Minibatch_Loss        lr\n",
      "24046  0.845038        0.416905  0.089419\n",
      "        Dev_Acc  Minibatch_Loss        lr\n",
      "26359  0.846369        0.388654  0.086884\n",
      "        Dev_Acc  Minibatch_Loss        lr\n",
      "28673  0.851539        0.337905  0.084373\n",
      "        Dev_Acc  Minibatch_Loss        lr\n",
      "30983  0.856242        0.352313  0.081389\n",
      "        Dev_Acc  Minibatch_Loss        lr\n",
      "33297  0.859435        0.293236  0.078486\n",
      "        Dev_Acc  Minibatch_Loss        lr\n",
      "35608  0.865967        0.286361  0.075121\n",
      "        Dev_Acc  Minibatch_Loss        lr\n",
      "37918  0.871917        0.313738  0.071393\n",
      "        Dev_Acc  Minibatch_Loss        lr\n",
      "40230  0.876081        0.315835  0.067896\n",
      "        Dev_Acc  Minibatch_Loss        lr\n",
      "42540  0.875387        0.288753  0.064018\n",
      "        Dev_Acc  Minibatch_Loss       lr\n",
      "44853  0.880526        0.282314  0.06039\n",
      "        Dev_Acc  Minibatch_Loss        lr\n",
      "47163  0.887619        0.235187  0.056403\n",
      "       Dev_Acc  Minibatch_Loss        lr\n",
      "49478  0.89168        0.258769  0.052699\n",
      "        Dev_Acc  Minibatch_Loss        lr\n",
      "51788  0.897454        0.257551  0.048676\n",
      "        Dev_Acc  Minibatch_Loss        lr\n",
      "54096  0.898369        0.302831  0.044467\n",
      "        Dev_Acc  Minibatch_Loss        lr\n",
      "56410  0.900313        0.291124  0.040666\n",
      "        Dev_Acc  Minibatch_Loss        lr\n",
      "58721  0.904142        0.276131  0.036681\n",
      "        Dev_Acc  Minibatch_Loss        lr\n",
      "61034  0.907228        0.274676  0.033091\n",
      "        Dev_Acc  Minibatch_Loss        lr\n",
      "63343  0.909285        0.204999  0.029359\n",
      "        Dev_Acc  Minibatch_Loss        lr\n",
      "65655  0.914257        0.184469  0.026024\n",
      "        Dev_Acc  Minibatch_Loss        lr\n",
      "67963  0.917771        0.150813  0.022607\n",
      "        Dev_Acc  Minibatch_Loss        lr\n",
      "70275  0.920714        0.139066  0.019236\n",
      "        Dev_Acc  Minibatch_Loss        lr\n",
      "72588  0.924676        0.195816  0.016322\n",
      "        Dev_Acc  Minibatch_Loss        lr\n",
      "74899  0.926251        0.166885  0.013476\n",
      "        Dev_Acc  Minibatch_Loss        lr\n",
      "77212  0.929501        0.155438  0.011045\n",
      "       Dev_Acc  Minibatch_Loss        lr\n",
      "79522   0.9332        0.131293  0.008734\n",
      "       Dev_Acc  Minibatch_Loss        lr\n",
      "81836    0.935        0.106756  0.006808\n"
     ]
    }
   ],
   "source": [
    "trainer = makeTrainer()\n",
    "trainer.train(train_epochs)\n",
    "trainer.save_checkpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Dev_Acc  Minibatch_Loss        lr\n",
      "92009  0.940239        0.052646  0.000746\n"
     ]
    }
   ],
   "source": [
    "trainer.optimizer.swap_swa_sgd()\n",
    "trainer.optimizer.bn_update(trainer.dataloaders['train'],trainer.model)\n",
    "trainer.logStuff(2008)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
