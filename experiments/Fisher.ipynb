{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch, torchvision\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "from contextlib import contextmanager\n",
    "\n",
    "from oil.cnnTrainer import CnnTrainer\n",
    "from oil.datasets import CIFAR10, C10augLayers\n",
    "from oil.networkparts import layer13\n",
    "from oil.schedules import cosLr\n",
    "from oil.utils import to_gpu\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_epochs = 150\n",
    "net_config =        {'numClasses':10}\n",
    "opt_config =        {'lr':.1, 'momentum':.9, 'weight_decay':1e-4, 'nesterov':True}\n",
    "sched_config =      {'cycle_length':train_epochs,'cycle_mult':1}\n",
    "trainer_config =    {'amntLab':1, 'amntDev':5000,'dataseed':0,\n",
    "                    'lab_BS':50, 'num_workers':4, 'log':False, \n",
    "                    }\n",
    "trainer_config['description'] = \"13Layer network, {} dev\".format(trainer_config['amntDev'])\n",
    "savedir = None#'/home/maf388/tb-experiments/layer13dev/'\n",
    "\n",
    "def makeTrainer():\n",
    "    CNN = layer13(**net_config)\n",
    "    fullCNN = nn.Sequential(C10augLayers(),CNN)\n",
    "    datasets = CIFAR10(aug=False)\n",
    "    opt_constr = lambda params: optim.SGD(params, **opt_config)\n",
    "    lr_lambda = cosLr(**sched_config)\n",
    "    return CnnTrainer(fullCNN, datasets, opt_constr, lr_lambda, **trainer_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Creating Train, Dev split         with 45000 Train and 5000 Dev\n",
      "=> loading checkpoint '/home/maf388/tb-experiments/layer13dev/checkpoints/c.150.ckpt'\n"
     ]
    }
   ],
   "source": [
    "trainer = makeTrainer()\n",
    "trainer.load_checkpoint('/home/maf388/tb-experiments/layer13dev/checkpoints/c.150.ckpt')\n",
    "_ = trainer.CNN.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9442"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.getAccuracy(trainer.dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fdFvpBatch(trainer, vec, trainData, eps=1, stencil=[-1,1]):\n",
    "    vlist = unflatten_like(vec, trainer.CNN.parameters())\n",
    "    derivLogP = 0\n",
    "    for i, c in enumerate(stencil):\n",
    "        with add(net, vlist, mul=eps*(i-(len(stencil)-1)/2)):\n",
    "            logits = trainer.CNN(*traindata)\n",
    "            logPk = nn.LogSoftmax(dim=1)(logits)\n",
    "            derivLogP += c*logPk.detach()/eps\n",
    "    with torch.autograd.enable_grad():\n",
    "        logits = trainer.CNN(*traindata)\n",
    "        Pk = nn.Softmax(dim=1)(logits)\n",
    "        score = torch.dot(Pk, derivLogP)\n",
    "        Fvp_list = torch.aurograd.grad(score, trainer.CNN.parameters())\n",
    "    return flatten(Fvp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-10-f833bef3d394>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-f833bef3d394>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    def autoFvpBatch(trainer,vec, trainData)\u001b[0m\n\u001b[0m                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def autoFvpBatch(trainer,vec, trainData):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple example sanity check\n",
    "class Toy(nn.Module):\n",
    "    def __init__(self, a1, a2):\n",
    "        super().__init__()\n",
    "        self.a1 = a1\n",
    "        self.a2 = a2\n",
    "    def forward(self, A1, A2):\n",
    "        return F.bilinear(self.a1,self.a1,A1)+F.bilinear(self.a2,self.a2,A2)\n",
    "        \n",
    "class ToyTrainer(object):\n",
    "    def __init__(self):\n",
    "        self.A1 = torch.eye(5)\n",
    "        self.A1[2,2]=3\n",
    "        self.A1[4,4]=-1\n",
    "        m = torch.normal(torch.zeros(5,5))\n",
    "        _,rot = torch.symeig(m.t()+m,eigenvectors=True)\n",
    "        self.A1 = torch.mm(rot, self.A1)\n",
    "        self.A2 = torch.eye(10)\n",
    "        self.CNN = Toy(torch.zeros(5),torch.ones(10))\n",
    "        \n",
    "    def loss(self, *trainData):\n",
    "        return self.CNN(self.A1, self.A2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
